{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.4.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.12/site-packages (from sentence_transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence_transformers)\n",
      "  Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.12/site-packages (from sentence_transformers) (1.15.1)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.17.0)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Downloading fsspec-2025.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
      "Collecting networkx (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached jinja2-3.1.5-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence_transformers) (75.8.0)\n",
      "Collecting sympy==1.13.1 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.7 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence_transformers)\n",
      "  Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2025.1.31)\n",
      "Downloading sentence_transformers-3.4.1-py3-none-any.whl (275 kB)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Downloading torch-2.6.0-cp312-none-macosx_11_0_arm64.whl (66.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hUsing cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pillow-11.1.0-cp312-cp312-macosx_11_0_arm64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2025.2.0-py3-none-any.whl (184 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl (173 kB)\n",
      "Downloading safetensors-0.5.2-cp38-abi3-macosx_11_0_arm64.whl (408 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-macosx_11_0_arm64.whl (2.6 MB)\n",
      "Using cached jinja2-3.1.5-py3-none-any.whl (134 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached MarkupSafe-3.0.2-cp312-cp312-macosx_11_0_arm64.whl (12 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, safetensors, pyyaml, Pillow, networkx, MarkupSafe, fsspec, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence_transformers\n",
      "Successfully installed MarkupSafe-3.0.2 Pillow-11.1.0 fsspec-2025.2.0 huggingface-hub-0.28.1 jinja2-3.1.5 mpmath-1.3.0 networkx-3.4.2 pyyaml-6.0.2 safetensors-0.5.2 sentence_transformers-3.4.1 sympy-1.13.1 tokenizers-0.21.0 torch-2.6.0 transformers-4.48.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23, 384)\n",
      "tensor([[1.0000, 0.4874, 0.5413, 0.6462, 0.5059, 0.5842, 0.5678, 0.5657, 0.4091,\n",
      "         0.6140, 0.5661, 0.5699, 0.5879, 0.7344, 0.6302, 0.5139, 0.6427, 0.6787,\n",
      "         0.5697, 0.5160, 0.5126, 0.6791, 0.5968],\n",
      "        [0.4874, 1.0000, 0.4287, 0.4204, 0.4573, 0.4860, 0.3970, 0.4376, 0.4247,\n",
      "         0.4270, 0.4082, 0.4354, 0.4866, 0.4651, 0.4968, 0.3410, 0.4770, 0.4174,\n",
      "         0.4570, 0.4089, 0.3415, 0.4421, 0.3991],\n",
      "        [0.5413, 0.4287, 1.0000, 0.7135, 0.4366, 0.5613, 0.3396, 0.6875, 0.3600,\n",
      "         0.6052, 0.5963, 0.7549, 0.6599, 0.6480, 0.5858, 0.6696, 0.6648, 0.6361,\n",
      "         0.6478, 0.7013, 0.4960, 0.6197, 0.6056],\n",
      "        [0.6462, 0.4204, 0.7135, 1.0000, 0.4044, 0.6643, 0.3717, 0.7501, 0.4758,\n",
      "         0.7020, 0.6224, 0.7514, 0.8501, 0.7184, 0.6846, 0.6557, 0.8531, 0.8210,\n",
      "         0.7166, 0.7691, 0.6743, 0.7263, 0.7400],\n",
      "        [0.5059, 0.4573, 0.4366, 0.4044, 1.0000, 0.4433, 0.3445, 0.4596, 0.6153,\n",
      "         0.4529, 0.4664, 0.4220, 0.4266, 0.5377, 0.5327, 0.3733, 0.4293, 0.4699,\n",
      "         0.4476, 0.3776, 0.3036, 0.5117, 0.4364],\n",
      "        [0.5842, 0.4860, 0.5613, 0.6643, 0.4433, 1.0000, 0.3294, 0.5722, 0.3780,\n",
      "         0.7234, 0.7404, 0.6349, 0.6313, 0.6681, 0.8120, 0.5429, 0.6141, 0.7401,\n",
      "         0.8306, 0.4955, 0.4595, 0.6801, 0.7997],\n",
      "        [0.5678, 0.3970, 0.3396, 0.3717, 0.3445, 0.3294, 1.0000, 0.3726, 0.3922,\n",
      "         0.3945, 0.2922, 0.3701, 0.4074, 0.3830, 0.3284, 0.3309, 0.4343, 0.3398,\n",
      "         0.3227, 0.3725, 0.3674, 0.4035, 0.3172],\n",
      "        [0.5657, 0.4376, 0.6875, 0.7501, 0.4596, 0.5722, 0.3726, 1.0000, 0.4802,\n",
      "         0.6406, 0.5675, 0.7370, 0.7559, 0.7873, 0.6133, 0.7007, 0.7248, 0.7242,\n",
      "         0.6346, 0.8011, 0.5619, 0.6701, 0.6333],\n",
      "        [0.4091, 0.4247, 0.3600, 0.4758, 0.6153, 0.3780, 0.3922, 0.4802, 1.0000,\n",
      "         0.3687, 0.3208, 0.3834, 0.5503, 0.4572, 0.5054, 0.3416, 0.5245, 0.3869,\n",
      "         0.3848, 0.4086, 0.4340, 0.4671, 0.3760],\n",
      "        [0.6140, 0.4270, 0.6052, 0.7020, 0.4529, 0.7234, 0.3945, 0.6406, 0.3687,\n",
      "         1.0000, 0.6861, 0.6642, 0.6895, 0.7226, 0.7475, 0.5506, 0.6702, 0.8940,\n",
      "         0.7593, 0.6195, 0.5477, 0.8279, 0.7392],\n",
      "        [0.5661, 0.4082, 0.5963, 0.6224, 0.4664, 0.7404, 0.2922, 0.5675, 0.3208,\n",
      "         0.6861, 1.0000, 0.6363, 0.5899, 0.6482, 0.8079, 0.5489, 0.5514, 0.7063,\n",
      "         0.8132, 0.4850, 0.4355, 0.6927, 0.8233],\n",
      "        [0.5699, 0.4354, 0.7549, 0.7514, 0.4220, 0.6349, 0.3701, 0.7370, 0.3834,\n",
      "         0.6642, 0.6363, 1.0000, 0.7102, 0.7209, 0.6445, 0.7968, 0.6895, 0.7089,\n",
      "         0.7185, 0.7901, 0.5882, 0.6744, 0.7408],\n",
      "        [0.5879, 0.4866, 0.6599, 0.8501, 0.4266, 0.6313, 0.4074, 0.7559, 0.5503,\n",
      "         0.6895, 0.5899, 0.7102, 1.0000, 0.7164, 0.6678, 0.6180, 0.8480, 0.7552,\n",
      "         0.6750, 0.7656, 0.6679, 0.7289, 0.6824],\n",
      "        [0.7344, 0.4651, 0.6480, 0.7184, 0.5377, 0.6681, 0.3830, 0.7873, 0.4572,\n",
      "         0.7226, 0.6482, 0.7209, 0.7164, 1.0000, 0.6904, 0.6623, 0.6710, 0.7937,\n",
      "         0.6805, 0.6826, 0.5595, 0.7883, 0.6773],\n",
      "        [0.6302, 0.4968, 0.5858, 0.6846, 0.5327, 0.8120, 0.3284, 0.6133, 0.5054,\n",
      "         0.7475, 0.8079, 0.6445, 0.6678, 0.6904, 1.0000, 0.5691, 0.6137, 0.7641,\n",
      "         0.8356, 0.5055, 0.5095, 0.7618, 0.8567],\n",
      "        [0.5139, 0.3410, 0.6696, 0.6557, 0.3733, 0.5429, 0.3309, 0.7007, 0.3416,\n",
      "         0.5506, 0.5489, 0.7968, 0.6180, 0.6623, 0.5691, 1.0000, 0.5751, 0.6206,\n",
      "         0.6179, 0.7087, 0.5133, 0.5896, 0.6453],\n",
      "        [0.6427, 0.4770, 0.6648, 0.8531, 0.4293, 0.6141, 0.4343, 0.7248, 0.5245,\n",
      "         0.6702, 0.5514, 0.6895, 0.8480, 0.6710, 0.6137, 0.5751, 1.0000, 0.7340,\n",
      "         0.6246, 0.7570, 0.6479, 0.7118, 0.6467],\n",
      "        [0.6787, 0.4174, 0.6361, 0.8210, 0.4699, 0.7401, 0.3398, 0.7242, 0.3869,\n",
      "         0.8940, 0.7063, 0.7089, 0.7552, 0.7937, 0.7641, 0.6206, 0.7340, 1.0000,\n",
      "         0.7708, 0.6956, 0.6043, 0.8435, 0.7756],\n",
      "        [0.5697, 0.4570, 0.6478, 0.7166, 0.4476, 0.8306, 0.3227, 0.6346, 0.3848,\n",
      "         0.7593, 0.8132, 0.7185, 0.6750, 0.6805, 0.8356, 0.6179, 0.6246, 0.7708,\n",
      "         1.0000, 0.5968, 0.5243, 0.7176, 0.8623],\n",
      "        [0.5160, 0.4089, 0.7013, 0.7691, 0.3776, 0.4955, 0.3725, 0.8011, 0.4086,\n",
      "         0.6195, 0.4850, 0.7901, 0.7656, 0.6826, 0.5055, 0.7087, 0.7570, 0.6956,\n",
      "         0.5968, 1.0000, 0.5812, 0.6136, 0.5808],\n",
      "        [0.5126, 0.3415, 0.4960, 0.6743, 0.3036, 0.4595, 0.3674, 0.5619, 0.4340,\n",
      "         0.5477, 0.4355, 0.5882, 0.6679, 0.5595, 0.5095, 0.5133, 0.6479, 0.6043,\n",
      "         0.5243, 0.5812, 1.0000, 0.5665, 0.5432],\n",
      "        [0.6791, 0.4421, 0.6197, 0.7263, 0.5117, 0.6801, 0.4035, 0.6701, 0.4671,\n",
      "         0.8279, 0.6927, 0.6744, 0.7289, 0.7883, 0.7618, 0.5896, 0.7118, 0.8435,\n",
      "         0.7176, 0.6136, 0.5665, 1.0000, 0.7107],\n",
      "        [0.5968, 0.3991, 0.6056, 0.7400, 0.4364, 0.7997, 0.3172, 0.6333, 0.3760,\n",
      "         0.7392, 0.8233, 0.7408, 0.6824, 0.6773, 0.8567, 0.6453, 0.6467, 0.7756,\n",
      "         0.8623, 0.5808, 0.5432, 0.7107, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# 1. Load a pretrained Sentence Transformer model\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# Các câu tiếng Việt để mã hóa\n",
    "sentences = [\n",
    "    \"Thời tiết hôm nay thật đẹp.\",\n",
    "    \"Trời nắng quá!\",\n",
    "    \"Anh ấy lái xe đến sân vận động.\",\n",
    "    \"Cô ấy đang đọc sách.\",\n",
    "    \"Tôi thích ăn kem.\",\n",
    "    \"Chúng tôi đi dạo trong công viên.\",\n",
    "    \"Hôm nay là một ngày tuyệt vời.\",\n",
    "    \"Anh ấy đang học lập trình.\",\n",
    "    \"Cô ấy thích nghe nhạc.\",\n",
    "    \"Tôi đang viết một bài báo.\",\n",
    "    \"Chúng tôi đang xem phim.\",\n",
    "    \"Anh ấy đang chơi bóng đá.\",\n",
    "    \"Cô ấy đang nấu ăn.\",\n",
    "    \"Tôi đang học tiếng Anh.\",\n",
    "    \"Chúng tôi đang làm việc nhóm.\",\n",
    "    \"Anh ấy đang chơi đàn guitar.\",\n",
    "    \"Cô ấy đang vẽ tranh.\",\n",
    "    \"Tôi đang đọc báo.\",\n",
    "    \"Chúng tôi đang uống cà phê.\",\n",
    "    \"Anh ấy đang chạy bộ.\",\n",
    "    \"Cô ấy đang tập yoga.\",\n",
    "    \"Tôi đang viết nhật ký.\",\n",
    "    \"Chúng tôi đang chơi cờ.\"\n",
    "]\n",
    "\n",
    "# 2. Calculate embeddings by calling model.encode()\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings.shape)\n",
    "# [3, 384]\n",
    "\n",
    "# 3. Calculate the embedding similarities\n",
    "similarities = model.similarity(embeddings, embeddings)\n",
    "print(similarities)\n",
    "# tensor([[1.0000, 0.6660, 0.1046],\n",
    "#         [0.6660, 1.0000, 0.1411],\n",
    "#         [0.1046, 0.1411, 1.0000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The two sentences with the highest similarity are:\n",
      "1. Tôi đang viết một bài báo.\n",
      "2. Tôi đang đọc báo.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Find the indices of the two sentences with the highest similarity\n",
    "similarities_np = similarities.numpy()\n",
    "np.fill_diagonal(similarities_np, -np.inf)  # Ignore self-similarity\n",
    "max_indices = np.unravel_index(np.argmax(similarities_np), similarities_np.shape)\n",
    "\n",
    "# Extract the sentences\n",
    "sentence1 = sentences[max_indices[0]]\n",
    "sentence2 = sentences[max_indices[1]]\n",
    "\n",
    "print(f\"The two sentences with the highest similarity are:\\n1. {sentence1}\\n2. {sentence2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tôi đang viết một bài báo. \t\t Tôi đang đọc báo. \t\t Score: 0.8940\n",
      "Chúng tôi đang uống cà phê. \t\t Chúng tôi đang chơi cờ. \t\t Score: 0.8623\n",
      "Chúng tôi đang làm việc nhóm. \t\t Chúng tôi đang chơi cờ. \t\t Score: 0.8567\n",
      "Cô ấy đang đọc sách. \t\t Cô ấy đang vẽ tranh. \t\t Score: 0.8531\n",
      "Cô ấy đang đọc sách. \t\t Cô ấy đang nấu ăn. \t\t Score: 0.8501\n",
      "Cô ấy đang nấu ăn. \t\t Cô ấy đang vẽ tranh. \t\t Score: 0.8480\n",
      "Tôi đang đọc báo. \t\t Tôi đang viết nhật ký. \t\t Score: 0.8435\n",
      "Chúng tôi đang làm việc nhóm. \t\t Chúng tôi đang uống cà phê. \t\t Score: 0.8356\n",
      "Chúng tôi đi dạo trong công viên. \t\t Chúng tôi đang uống cà phê. \t\t Score: 0.8306\n",
      "Tôi đang viết một bài báo. \t\t Tôi đang viết nhật ký. \t\t Score: 0.8279\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers.util import paraphrase_mining\n",
    "\n",
    "paraphrases = paraphrase_mining(model, sentences)\n",
    "\n",
    "for paraphrase in paraphrases[0:10]:\n",
    "    score, i, j = paraphrase\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
